import sys
import numpy as np
import re
import pandas as pd
import os
import glob
NUM_STATES = 12
NUM_WINDOWS_PER_FILE = 10000

# chromsomes (each call to flatten_chromosome_state_files.py)
    # samples (loop within flatten() )
        # open chromosome-sample file
        # partitions (loop within other loop)
            # open partition file for this chromosome-sample-partition

def flatten(sample_list, data_dir, chrom_name, chrom_num, state_order, chrom_partition_list, out_dir):
    # iterate over the chromosome file in question for each sample
    for sample in sample_list:
        # get this sample's chrom file
        chrom_file = glob.glob(os.path.join(data_dir, sample + '*' + chrom_name + '_posterior.txt'))
        #raise error if for some reason the sampel is not found
        try:
            chrom_fn = chrom_file[0]
        except:
            sys.exit('no file for this sample and chromosome found in data_dir')
        # read in one chromosome data file
        # # TODO: make this have some logic to check if the first row is headers or the 2 element row we want to ignore bc it depends on if the chrom files ave been preprocessed or not
        whole_chrom_df = pd.read_csv(chrom_fn, sep='\t', skiprows=1)
        # write segments of this whole_chrom_df to each partition_df
        for partition_num in range(2):
        #for partition_num in range(len(chrom_partition_list)):
            partition_tup = chrom_partition_list[partition_num]
            partition_fn = os.path.join(out_dir, "{}_{}.tsv".format(chrom_name, partition_num))
            # get the rows for this partition
            to_flatten_df = whole_chrom_df.iloc[partition_tup[0]:partition_tup[1]+1]
            # flattend this partition df into one row
            this_flat_row_df = flatten_one_partition(to_flatten_df, state_order, sample, chrom_name)
            # open this chrom, sample, partition file or if it does not exist, create it
            # add the new row to flat_df and save it
            try:
                print(\n)
                partition_df = pd.read_csv(partition_fn, sep = '\t')
                print(partition_df)
                print(this_flat_row_df)
                partition_df.append(this_flat_row_df.loc[sample], ignore_index=True)
                print(partition_df)
                print(\n)
            except:
                print(\n)
                print("here")
                # if the partition df does not exist yet
                partition_df = this_flat_row_df
                print(partition_df)
                print(\n)
            partition_df.to_csv(partition_fn, sep='\t')

def flatten_one_partition(to_flatten_df, state_order, sample, chrom_name):
        # flatten the matrix
        chrom_df = to_flatten_df.rename_axis('window').reset_index().melt('window', value_name = sample, var_name='state')
        chrom_df['state'] = chrom_df['state'].astype(state_order)
        chrom_df = chrom_df.sort_values(['window', 'state'])
        chrom_df['chr_window_state'] = chrom_name + '_' + chrom_df['window'].astype(str) + '_' + chrom_df['state'].astype(str)
        chrom_df.drop(['window','state'], inplace = True, axis = 1)
        # transpose so first row is window_state and second is posterior value
        chrom_df = chrom_df.set_index('chr_window_state').transpose()
        return chrom_df


def split_chrom_len(chrom_len):
    # return a list of tuples of window indeces for each new file
    # the tuples are (num of first window in file, num of last window in file)
    num_files = chrom_len // NUM_WINDOWS_PER_FILE
    if num_files % NUM_WINDOWS_PER_FILE != 0:
        leftover = chrom_len % NUM_WINDOWS_PER_FILE
        num_files += 1
    chrom_partition_list = []
    for file_num in range(num_files):
        if file_num == num_files - 1:
            tup = (file_num * NUM_WINDOWS_PER_FILE, file_num * NUM_WINDOWS_PER_FILE + leftover)
            chrom_partition_list.append(tup)
        else:
            tup = (file_num * NUM_WINDOWS_PER_FILE, (file_num + 1) * NUM_WINDOWS_PER_FILE - 1)
            chrom_partition_list.append(tup)
    return chrom_partition_list


"""
flatten_chromosome_state_files.py
@ this script takes all the posterior files for a given chromosome, breaks them into smaller 10k window pieces, and flattens them so that each row is a sample and the columns are the 10k*12 states
"""

def main():
    # read command line args
    chrom_num = str(sys.argv[1])
    chrom_name = 'chr' + str(chrom_num)

    # create an ordering of states to later use in sorting
    states_list = ['E' + str(i) for i in range(1,13)]
    state_order = pd.CategoricalDtype(states_list, ordered = True)

    # create a list of all the blueprint sample names
    with open("../blueprint_data/blueprint_sample_list.txt") as f:
        sample_list = f.readlines()
        sample_list = [sample.rstrip() for sample in sample_list]

    data_dir = "../blueprint_data/raw_data"
    out_dir = "../blueprint_data/processed_data"

    # get the length in windows of the chromosome
    chrom_len_df = pd.read_csv("../blueprint_data/chromosome_lengths.tsv", sep = '\t')
    this_chrom_len = int(chrom_len_df['Length'][int(chrom_num) - 1])

    # break into 100K window sections
    # returns a list of tuples like this [(0, 99999), (100000, 199999), (200000, 299999), (300000, 399999), (400000, 499999), (500000, 599999), (600000, 699999), (700000, 799999), (800000, 899999), (900000, 999999), (1000000, 1099999), (1100000, 1199999), (1200000, 1244782)]
    chrom_partition_list = split_chrom_len(this_chrom_len)
    print(chrom_partition_list)

    flatten(sample_list, data_dir, chrom_name, chrom_num, state_order, chrom_partition_list, out_dir)

main()
